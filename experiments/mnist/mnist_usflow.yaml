---
__object__: src.explib.base.ExperimentCollection
name: mnist_ablation
experiments:
  - &exp_laplace
    __object__: src.explib.hyperopt.HyperoptExperiment
    name: mnist_full_radial_logN
    scheduler: &scheduler 
      __object__: ray.tune.schedulers.ASHAScheduler
      max_t: 1000000
      grace_period: 1000000
      reduction_factor: 2
    num_hyperopt_samples: &num_hyperopt_samples 1
    gpus_per_trial: &gpus_per_trial 1
    cpus_per_trial: &cpus_per_trial 1
    tuner_params: &tuner_params
      metric: val_loss
      mode: min
    device: cuda
    trial_config:
      logging:
        images: false
        "image_shape": [28, 28]
      dataset: &dataset
        __object__: src.explib.datasets.MnistSplit
        space_to_depth_factor: 2
        device: cuda 
      epochs: &epochs 200000
      patience: &patience 2
      batch_size: &batch_size 
        __eval__: tune.choice([32])
      optim_cfg: &optim 
        optimizer:
          __class__: torch.optim.Adam 
        params:
          lr: 
            __eval__: 1e-4
          weight_decay: 0.0
      
      model_cfg: 
        type:
          __class__: &model src.veriflow.flows.USFlow
        params:
          soft_training: false
          training_noise_prior:
            __object__: pyro.distributions.Uniform
            low: 
              __eval__: 1e-20
            high: 0.01
          prior_scale: 1.0
          coupling_blocks: 1
          conditioner_cls: 
            __class__: src.veriflow.networks.ConvNet2D
          conditioner_args:
            c_in: 4
            num_layers: 3
          in_dims: [4, 14, 14]
          affine_conjugation: true
          nonlinearity: &nonlinearity 
            __eval__: tune.choice([torch.nn.ReLU()])
          base_distribution: 
            __object__: pyro.distributions.Laplace
            loc: 
              __eval__: torch.zeros([4, 14, 14]).to("cuda")
            scale: 
              __eval__: torch.ones([4, 14, 14]).to("cuda")
          use_lu: true
